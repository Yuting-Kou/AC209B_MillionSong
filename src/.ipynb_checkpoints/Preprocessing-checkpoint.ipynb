{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(r'../data/music.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature engineering\n",
    "\n",
    "1. generate decades: missing data fill 0\n",
    "2. artist name : generate first and last characters of the artist name. string type\n",
    "3. artist mtbags: artist genre. \n",
    "   - generate number of artist genre.\n",
    "   - turn string into id in atmost 3 genre.\n",
    "4. similar: turn similar into the hotness of the similar artists.\n",
    "5. terms: turn string into id\n",
    "6. remove outlier:trim  huge outlier into [0,1]\n",
    "    - terms_freq\n",
    "    - time_signature_confidence\n",
    "7. generate tf-idf sparse matrix：\n",
    "    - title\n",
    "    - release name\n",
    "8. drop location related columns:\n",
    "    - latitude\n",
    "    - longitude\n",
    "    - location\n",
    "    \n",
    "### future possible feature engineering\n",
    "1. generate sentiment analysis on title and release name\n",
    "2. turn the string variable (non-ordered) into dummy or other feature extraction methods like PCA:\n",
    "    - artist first and last name\n",
    "    - mtbags: mtbag_1, mtbag_2, mtbag_3\n",
    "    - term_id\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(corpus,stop_words=stop_words,stem = False):\n",
    "    result = []\n",
    "    ps = PorterStemmer() \n",
    "    for i in corpus:\n",
    "        if stem:\n",
    "            song = ' '.join([ps.stem(j) for j in i.split() if j not in stop_words])\n",
    "        else:\n",
    "            song = ' '.join([j for j in i.split() if j not in stop_words])\n",
    "        result.append(song)        \n",
    "    return result\n",
    "\n",
    "def tf_idf(corpus):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tf_df = vectorizer.fit_transform(corpus)\n",
    "    return tf_df,vectorizer\n",
    "\n",
    "def generate_tf_idf(se):\n",
    "    # ------------------------ release name or title ------------------------------------------------- #\n",
    "    # turn to tf-idf matrix\n",
    "    release_name = remove_stopwords(se.fillna(''),stem=True)\n",
    "    release_tfidf,release_voc = tf_idf(release_name)\n",
    "    return release_tfidf,release_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    # ----------------------- generate decades ------------------------------------- #\n",
    "    data['decade']=data.year.apply(lambda se: se//10*10)\n",
    "\n",
    "    # ----------------------- artist name ------------------------------------------ #\n",
    "    data['artist_firstname']=data['artist.name'].apply(lambda se:se[0].upper())\n",
    "    data['artist_lastname']=data['artist.name'].apply(lambda se: se.split(' ')[-1][:1].upper() )\n",
    "    \n",
    "    # ----------------------- mtbags ------------------------------------------------ #\n",
    "    '''\n",
    "    \"Terms\" are the tags provided by The Echo Nest. They can come from a number of places, but mostly blogs as far as we understand. \n",
    "     \"Mbtags\" are musicbrainz tags, specifically applied by humans to a particular artist. This explains why there are fewer of them \n",
    "     (see 'mbtags_count'), but they are usually very clean and informative. \n",
    "     For instance, if you want to create a genre recognition task where classes are mutually exclusive, mbtags are likely to be more \n",
    "     reliable then terms.\n",
    "    '''\n",
    "    # total 284 mtbags, but at most 3 tags per songs. \n",
    "    # Creat 3 columns for the songs tags\n",
    "    mbtags = data['artist_mbtags'].apply(lambda se: [x.strip() for x in se.split('and')] if type(se)==str else np.nan)\n",
    "    unique_tags = set(mbtags.dropna().sum())\n",
    "    n_tags = len(unique_tags)\n",
    "    tag2idx=dict(zip(unique_tags,range(1,n_tags+1)))\n",
    "    tag2idx[np.nan]=0\n",
    "    idx2tag=dict(zip(range(1,n_tags+1),unique_tags))\n",
    "    idx2tag[0]=np.nan\n",
    "    data['mbtags_count']=mbtags.apply(lambda se:len(se) if type(se)==list else 0)\n",
    "    n_tags_per_song = data['mbtags_count'].max()\n",
    "    a=mbtags.apply(lambda se:[tag2idx[k] for k in se]+[0]*(3-len(se)) if type(se)==list else [0,0,0]).apply(pd.Series)\n",
    "    a.columns=['mbtag_'+str(i) for i in range(n_tags_per_song)]\n",
    "    data=pd.concat([data,a],axis=1)\n",
    "    \n",
    "    # -------------------------- similar --------------------------------------------------- #\n",
    "    # turn similar to the hotness of the similar artists\n",
    "    artist_hot=data[['artist.id','artist.hotttnesss']].drop_duplicates()\n",
    "    id2hot = defaultdict(lambda:np.nan,zip(artist_hot['artist.id'], artist_hot['artist.hotttnesss']))\n",
    "    data['similar_hotness']=data['similar'].apply(lambda se:id2hot[se])\n",
    "    \n",
    "    # -------------------------- terms ------------------------------------------------------ #\n",
    "    # turn the terms to id\n",
    "    terms = data['terms'].unique()\n",
    "    data['terms_freq'][data['terms_freq']>1]=1\n",
    "    n_terms = len(terms)\n",
    "    term2idx=dict(zip(terms,range(1,n_terms+1)))\n",
    "    term2idx[np.nan]=0\n",
    "    idx2term=dict(zip(range(1,n_terms+1),terms))\n",
    "    idx2term[0]=np.nan\n",
    "    data['term_id']=data['terms'].apply(lambda se:term2idx[se] )\n",
    "    \n",
    "    # --------------------------- remove the outliers ---------------------------------------- #\n",
    "    data['terms_freq'][data['terms_freq']>1]=1\n",
    "    data['time_signature_confidence'][data['time_signature_confidence']>1]=1\n",
    "    \n",
    "    # ---------------------------- to do ------------------------------------------------------ #\n",
    "    # add sentiment analysis on title and release name.\n",
    "    \n",
    "    \n",
    "    return data, tag2idx,idx2tag, term2idx,idx2term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data,tag2idx,idx2tag,term2idx,idx2term=preprocess(data)\n",
    "# data.to_csv(r'..\\data\\music_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the data from disk and work from now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'../data/music_clean.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_tfidf,release_voc=generate_tf_idf(data['release.name'])\n",
    "title_tfidf,title_voc=generate_tf_idf(data['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist.hotttnesss</th>\n",
       "      <th>artist_mbtags_count</th>\n",
       "      <th>bars_confidence</th>\n",
       "      <th>bars_start</th>\n",
       "      <th>beats_confidence</th>\n",
       "      <th>beats_start</th>\n",
       "      <th>duration</th>\n",
       "      <th>end_of_fade_in</th>\n",
       "      <th>familiarity</th>\n",
       "      <th>key</th>\n",
       "      <th>...</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>time_signature_confidence</th>\n",
       "      <th>year</th>\n",
       "      <th>decade</th>\n",
       "      <th>mbtags_count</th>\n",
       "      <th>mbtag_0</th>\n",
       "      <th>mbtag_1</th>\n",
       "      <th>mbtag_2</th>\n",
       "      <th>similar_hotness</th>\n",
       "      <th>term_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9996.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>2316.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.385552</td>\n",
       "      <td>0.524686</td>\n",
       "      <td>0.239595</td>\n",
       "      <td>1.065246</td>\n",
       "      <td>0.613963</td>\n",
       "      <td>0.428497</td>\n",
       "      <td>240.622038</td>\n",
       "      <td>0.756708</td>\n",
       "      <td>0.565456</td>\n",
       "      <td>5.366580</td>\n",
       "      <td>...</td>\n",
       "      <td>3.564443</td>\n",
       "      <td>0.509996</td>\n",
       "      <td>934.704600</td>\n",
       "      <td>932.431000</td>\n",
       "      <td>0.458800</td>\n",
       "      <td>52.183800</td>\n",
       "      <td>15.337700</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.441496</td>\n",
       "      <td>119.492500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.143647</td>\n",
       "      <td>0.884095</td>\n",
       "      <td>0.288259</td>\n",
       "      <td>1.723468</td>\n",
       "      <td>0.322441</td>\n",
       "      <td>0.806217</td>\n",
       "      <td>246.084090</td>\n",
       "      <td>1.858958</td>\n",
       "      <td>0.160161</td>\n",
       "      <td>9.671788</td>\n",
       "      <td>...</td>\n",
       "      <td>1.266620</td>\n",
       "      <td>0.373440</td>\n",
       "      <td>996.650657</td>\n",
       "      <td>994.225985</td>\n",
       "      <td>0.651111</td>\n",
       "      <td>84.253195</td>\n",
       "      <td>54.517359</td>\n",
       "      <td>1.7800</td>\n",
       "      <td>0.134207</td>\n",
       "      <td>100.028535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>1.044440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.325266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.441590</td>\n",
       "      <td>0.409750</td>\n",
       "      <td>0.194655</td>\n",
       "      <td>176.032200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467611</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.097750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.372227</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.380742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.785460</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>0.332585</td>\n",
       "      <td>223.059140</td>\n",
       "      <td>0.199000</td>\n",
       "      <td>0.563666</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.551000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.421418</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.453858</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.351000</td>\n",
       "      <td>1.224075</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.500753</td>\n",
       "      <td>276.375060</td>\n",
       "      <td>0.421000</td>\n",
       "      <td>0.668020</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.526847</td>\n",
       "      <td>177.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.082503</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.855240</td>\n",
       "      <td>59.743540</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.245830</td>\n",
       "      <td>22050.000000</td>\n",
       "      <td>43.119000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>904.802810</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>1.021256</td>\n",
       "      <td>459.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       artist.hotttnesss  artist_mbtags_count  bars_confidence    bars_start  \\\n",
       "count       10000.000000         10000.000000     10000.000000  10000.000000   \n",
       "mean            0.385552             0.524686         0.239595      1.065246   \n",
       "std             0.143647             0.884095         0.288259      1.723468   \n",
       "min             0.000000             0.000000         0.000000      0.000000   \n",
       "25%             0.325266             0.000000         0.035000      0.441590   \n",
       "50%             0.380742             0.000000         0.120000      0.785460   \n",
       "75%             0.453858             1.000000         0.351000      1.224075   \n",
       "max             1.082503             9.000000         8.855240     59.743540   \n",
       "\n",
       "       beats_confidence   beats_start      duration  end_of_fade_in  \\\n",
       "count      10000.000000  10000.000000  10000.000000    10000.000000   \n",
       "mean           0.613963      0.428497    240.622038        0.756708   \n",
       "std            0.322441      0.806217    246.084090        1.858958   \n",
       "min            0.000000    -60.000000      1.044440        0.000000   \n",
       "25%            0.409750      0.194655    176.032200        0.000000   \n",
       "50%            0.686000      0.332585    223.059140        0.199000   \n",
       "75%            0.882000      0.500753    276.375060        0.421000   \n",
       "max            1.000000     12.245830  22050.000000       43.119000   \n",
       "\n",
       "       familiarity           key      ...       time_signature  \\\n",
       "count  9996.000000  10000.000000      ...         10000.000000   \n",
       "mean      0.565456      5.366580      ...             3.564443   \n",
       "std       0.160161      9.671788      ...             1.266620   \n",
       "min       0.000000      0.000000      ...             0.000000   \n",
       "25%       0.467611      2.000000      ...             3.000000   \n",
       "50%       0.563666      5.000000      ...             4.000000   \n",
       "75%       0.668020      8.000000      ...             4.000000   \n",
       "max       1.000000    904.802810      ...             7.000000   \n",
       "\n",
       "       time_signature_confidence          year        decade  mbtags_count  \\\n",
       "count               10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean                    0.509996    934.704600    932.431000      0.458800   \n",
       "std                     0.373440    996.650657    994.225985      0.651111   \n",
       "min                     0.000000      0.000000      0.000000      0.000000   \n",
       "25%                     0.097750      0.000000      0.000000      0.000000   \n",
       "50%                     0.551000      0.000000      0.000000      0.000000   \n",
       "75%                     0.864000   2000.000000   2000.000000      1.000000   \n",
       "max                     1.000000   2010.000000   2010.000000      3.000000   \n",
       "\n",
       "            mbtag_0       mbtag_1     mbtag_2  similar_hotness       term_id  \n",
       "count  10000.000000  10000.000000  10000.0000      2316.000000  10000.000000  \n",
       "mean      52.183800     15.337700      0.0178         0.441496    119.492500  \n",
       "std       84.253195     54.517359      1.7800         0.134207    100.028535  \n",
       "min        0.000000      0.000000      0.0000         0.000000      0.000000  \n",
       "25%        0.000000      0.000000      0.0000         0.372227     40.000000  \n",
       "50%        0.000000      0.000000      0.0000         0.421418     94.000000  \n",
       "75%       93.000000      0.000000      0.0000         0.526847    177.000000  \n",
       "max      284.000000    281.000000    178.0000         1.021256    459.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
